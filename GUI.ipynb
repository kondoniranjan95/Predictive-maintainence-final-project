{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# We add all Plotly and Dash necessary librairies\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_daq as daq\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df= pd.read_csv(\"Data/predictive_maintainence.csv\")\n",
    "X= df.drop(columns=[\"process_id\",\"failure\"])\n",
    "Y= df[\"failure\"]\n",
    "\n",
    "\n",
    "corr = X.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(100, 10))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)\n",
    "\n",
    "cor_matrix = X.corr().abs()\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.79)]\n",
    "X = X.drop(columns=to_drop)\n",
    "X_colm= X.columns\n",
    "print(X_colm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_feature_importances = pd.DataFrame(model.feature_importances_*100,columns=[\"Importance\"],index=X_colm)\n",
    "df_feature_importances = df_feature_importances.sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "# We create a Features Importance Bar Chart\n",
    "fig_features_importance = go.Figure()\n",
    "fig_features_importance.add_trace(go.Bar(x=df_feature_importances.index,\n",
    "                                         y=df_feature_importances[\"Importance\"],\n",
    "                                         marker_color='rgb(171, 226, 251)')\n",
    "                                 )\n",
    "fig_features_importance.update_layout(title_text='<b>Features Importance of the model<b>', title_x=0.5)\n",
    "fig_features_importance.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We record the name, min, mean and max of the three most important features\n",
    "# We record the name, min, mean and max of the three most important features\n",
    "dropdown_1_label = df_feature_importances.index[0]\n",
    "dropdown_1_min = math.floor(df[dropdown_1_label].min())\n",
    "dropdown_1_mean = round(df[dropdown_1_label].mean())\n",
    "dropdown_1_max = round(df[dropdown_1_label].max())\n",
    "\n",
    "dropdown_2_label = df_feature_importances.index[1]\n",
    "dropdown_2_min = math.floor(df[dropdown_2_label].min())\n",
    "dropdown_2_mean = round(df[dropdown_2_label].mean())\n",
    "dropdown_2_max = round(df[dropdown_2_label].max())\n",
    "\n",
    "dropdown_3_label = df_feature_importances.index[2]\n",
    "dropdown_3_min = math.floor(df[dropdown_3_label].min())\n",
    "dropdown_3_mean = round(df[dropdown_3_label].mean())\n",
    "dropdown_3_max = round(df[dropdown_3_label].max())\n",
    "dropdown_3_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash()\n",
    "\n",
    "# The page structure will be:\n",
    "#    Features Importance Chart\n",
    "#    <H4> Feature #1 name\n",
    "#    Slider to update Feature #1 value\n",
    "#    <H4> Feature #2 name\n",
    "#    Slider to update Feature #2 value\n",
    "#    <H4> Feature #3 name\n",
    "#    Slider to update Feature #3 value\n",
    "#    <H2> Updated Prediction\n",
    "#    Callback fuction with Sliders values as inputs and Prediction as Output\n",
    "\n",
    "# We apply basic HTML formatting to the layout\n",
    "app.layout = html.Div(style={'textAlign': 'center', 'width': '800px', 'font-family': 'Verdana'},\n",
    "                      \n",
    "                    children=[\n",
    "\n",
    "                        # Title display\n",
    "                        html.H1(children=\"Simulation Tool\"),\n",
    "                        \n",
    "                        # Dash Graph Component calls the fig_features_importance parameters\n",
    "                        dcc.Graph(figure=fig_features_importance),\n",
    "                        \n",
    "                        # We display the most important feature's name\n",
    "                        html.H4(children=dropdown_1_label),\n",
    "\n",
    "                        # The Dash Slider is built according to Feature #1 ranges\n",
    "                        dcc.Slider(\n",
    "                            id='X1_slider',\n",
    "                            min=dropdown_1_min,\n",
    "                            max=dropdown_1_max,\n",
    "                            step=0.5,\n",
    "                            value=dropdown_1_mean,\n",
    "                            marks={i: '{}'.format(i) for i in range(dropdown_1_min, dropdown_1_max+1,25)}\n",
    "                            ),\n",
    "\n",
    "                        html.H4(children=dropdown_2_label),\n",
    "\n",
    "                        dcc.Slider(\n",
    "                            id='X2_slider',\n",
    "                            min=dropdown_2_min,\n",
    "                            max=dropdown_2_max,\n",
    "                            step=0.5,\n",
    "                            value=dropdown_2_mean,\n",
    "                            marks={i: '{}'.format(i) for i in range(dropdown_2_min, dropdown_2_max+1,10000)}\n",
    "                        ),\n",
    "\n",
    "                        html.H4(children=dropdown_3_label),\n",
    "\n",
    "                        dcc.Slider(\n",
    "                            id='X3_slider',\n",
    "                            min=dropdown_3_min,\n",
    "                            max=dropdown_3_max,\n",
    "                            step=0.5,\n",
    "                            value=dropdown_3_mean,\n",
    "                            marks={i: '{}'.format(i) for i in range(dropdown_3_min, dropdown_3_max+1,300)}\n",
    "                        ),\n",
    "\n",
    "                        html.H2(id=\"prediction_result\")\n",
    "\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The callback function will provide one \"Ouput\" in the form of a string (=children)\n",
    "@app.callback(Output(component_id=\"prediction_result\",component_property=\"children\"),\n",
    "# The values correspnding to the three sliders are obtained by calling their id and value property\n",
    "              [Input(\"X1_slider\",\"value\"), Input(\"X2_slider\",\"value\"), Input(\"X3_slider\",\"value\")])\n",
    "      \n",
    "def update_prediction(X1, X2, X3):\n",
    "    # We create a NumPy array in the form of the original features\n",
    "    # [\"Pressure\",\"Viscosity\",\"Particles_size\", \"Temperature\",\"Inlet_flow\", \"Rotating_Speed\",\"pH\",\"Color_density\"]\n",
    "    # Except for the X1, X2 and X3, all other non-influencing parameters are set to their mean\n",
    "    input_X= np.array([df['min_x_position'].mean(),df['avg_x_position'].mean(), df['avg_y_position'].mean(),df['avg_main_current'].mean(), df['max_noise'].mean(), df['avg_vibrations'].mean(), df['max_vibrations'].mean(),df['avg_z_position'].mean(), df['min_z_position'].mean(), df['penetration'].mean(), df['process_time'].mean(),X1, X2, df['luminosity'].mean(), X3,df['avg_main_force'].mean(),df['x_distance'].mean(), df['y_distance'].mean(), df['z_distance'].mean(), df['time_reference_diff'].mean(), df['x_pos_reference_diff'].mean(), df['z_pos_reference_diff'].mean(),df['off_limits_average'].mean(), df['position_range'].mean(), df['current_range'].mean(),df['current_signal_noise_ratio'].mean(), df['preparation_time'].mean]).reshape(1,-1)\n",
    "\n",
    "    # Prediction is calculated based on the input_X array\n",
    "    prediction = model.predict(input_X)[0]\n",
    "    \n",
    "    # And retuned to the Output of the callback function\n",
    "    return \"Prediction: {}\".format(round(prediction,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 27, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6760/1046117896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_X\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_x_position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_x_position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_y_position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_main_current'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_noise'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_vibrations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_vibrations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_z_position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_z_position'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'penetration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'process_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'luminosity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg_main_force'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z_distance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_reference_diff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_pos_reference_diff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z_pos_reference_diff'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'off_limits_average'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'position_range'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_range'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_signal_noise_ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preparation_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\DA_Envi\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[0miteration_range\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m-> 1284\u001b[1;33m         class_probs = super().predict(\n\u001b[0m\u001b[0;32m   1285\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\DA_Envi\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m                 predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[0;32m    882\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m                     \u001b[0miteration_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\DA_Envi\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2016\u001b[0m                 )\n\u001b[0;32m   2017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2018\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   2019\u001b[0m                     \u001b[1;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2020\u001b[0m                     \u001b[1;34mf\"got {data.shape[1]}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 27, got 1"
     ]
    }
   ],
   "source": [
    "input_X= pd.DataFrame([df['min_x_position'].mean(),df['avg_x_position'].mean(), df['avg_y_position'].mean(),df['avg_main_current'].mean(), df['max_noise'].mean(), df['avg_vibrations'].mean(), df['max_vibrations'].mean(),df['avg_z_position'].mean(), df['min_z_position'].mean(), df['penetration'].mean(), df['process_time'].mean(),5, 6, df['luminosity'].mean(), 7,df['avg_main_force'].mean(),df['x_distance'].mean(), df['y_distance'].mean(), df['z_distance'].mean(), df['time_reference_diff'].mean(), df['x_pos_reference_diff'].mean(), df['z_pos_reference_diff'].mean(),df['off_limits_average'].mean(), df['position_range'].mean(), df['current_range'].mean(),df['current_signal_noise_ratio'].mean(), df['preparation_time'].mean()])\n",
    "input_X\n",
    "prediction = model.predict(input_X)\n",
    "#prediction"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82e6290ce2c356cceb89c98c36079548bc3fbf6bc2b11ac043e55de0e1250e68"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('DA_Envi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
